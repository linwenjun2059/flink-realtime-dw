# å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿå¯åŠ¨

### å‰ç½®æ¡ä»¶æ£€æŸ¥
```bash
# æ£€æŸ¥Javaç‰ˆæœ¬ (éœ€è¦JDK 8+)
java -version

# æ£€æŸ¥Maven (éœ€è¦Maven 3.6+)
mvn -version

# æ£€æŸ¥Kafkaæ˜¯å¦è¿è¡Œ
kafka-topics.sh --list --bootstrap-server slave1:9092

# æ£€æŸ¥MySQLæ˜¯å¦è¿è¡Œ
mysql -h master1 -u root -p -e "SELECT VERSION();"

# æ£€æŸ¥ClickHouseæ˜¯å¦è¿è¡Œ
clickhouse-client --host slave1 --query "SELECT version()"

# æ£€æŸ¥Flinkæ˜¯å¦è¿è¡Œ
curl http://master1:8081
```

---

## ğŸ“ æ­¥éª¤1: åˆå§‹åŒ–æ•°æ®åº“ (2åˆ†é’Ÿ)

### åˆ›å»ºMySQLç»´åº¦è¡¨
```bash
cd flink-realtime-dw/mysql-dimension

# ä¿®æ”¹å¯†ç ï¼ˆå¦‚æœéœ€è¦ï¼‰
# ç¼–è¾‘ create_tables.sql, insert_user_data.sql, insert_product_data.sql
# å°† 'your_password' æ›¿æ¢ä¸ºå®é™…å¯†ç 

# æ‰§è¡Œå»ºè¡¨å’Œæ’å…¥æ•°æ®
mysql -h master1 -u root -p < create_tables.sql
mysql -h master1 -u root -p < insert_user_data.sql
mysql -h master1 -u root -p < insert_product_data.sql

# éªŒè¯
mysql -h master1 -u root -p flink_realtime_dw -e \
  "SELECT COUNT(*) FROM user_info; SELECT COUNT(*) FROM product_info;"
```

æœŸæœ›è¾“å‡ºï¼š
```
COUNT(*)
100

COUNT(*)
200
```

### åˆ›å»ºClickHouseè¡¨
```bash
cd ../clickhouse-grafana

# åœ¨slave1æ‰§è¡Œå»ºè¡¨è„šæœ¬
clickhouse-client -n < /opt/test/clickhouse_init.sql

#æˆ–è€…è¿œç¨‹æ‰§è¡Œ
clickhouse-client -n --host slave1 < clickhouse_init.sql
# éªŒè¯
clickhouse-client --host slave1 --query "SHOW TABLES FROM flink_metrics"
```

æœŸæœ›è¾“å‡ºï¼š
```
metrics_brand_top
metrics_category_top
metrics_city
metrics_time_window
metrics_user_level
```

---

## ğŸ“ æ­¥éª¤2: åˆ›å»ºKafka Topics (1åˆ†é’Ÿ)

```bash
# åˆ›å»ºè®¢å•ä¸»è¡¨Topic
kafka-topics.sh --create --if-not-exists \
  --bootstrap-server slave1:9092 \
  --topic order-main-source \
  --partitions 3 \
  --replication-factor 2

# åˆ›å»ºè®¢å•æ˜ç»†Topic
kafka-topics.sh --create --if-not-exists \
  --bootstrap-server slave1:9092 \
  --topic order-detail-source \
  --partitions 3 \
  --replication-factor 2

# åˆ›å»ºå®½è¡¨Topic
kafka-topics.sh --create --if-not-exists \
  --bootstrap-server slave1:9092 \
  --topic order-wide-topic \
  --partitions 3 \
  --replication-factor 2

# éªŒè¯
kafka-topics.sh --list --bootstrap-server slave1:9092 | grep order
```

æœŸæœ›è¾“å‡ºï¼š
```
order-detail-source
order-main-source
order-wide-topic
```

---

## ğŸ“ æ­¥éª¤3: ç¼–è¯‘é¡¹ç›® (2åˆ†é’Ÿ)

```bash
cd flink-realtime-dw

# ç¼–è¯‘æ•°æ®ç”Ÿæˆå™¨
echo "ç¼–è¯‘æ•°æ®ç”Ÿæˆå™¨..."
cd data-generator
mvn clean package -DskipTests
cd ..

# ç¼–è¯‘Flinkæ¸…æ´—ä½œä¸š (éœ€è¦è¡¥å……å®Œæ•´ä»£ç )
echo "ç¼–è¯‘Flinkæ¸…æ´—ä½œä¸š..."
cd flink-cleansing
# æ³¨æ„ï¼šéœ€è¦æ ¹æ® IMPLEMENTATION_GUIDE.md å®Œæˆæ ¸å¿ƒä»£ç 
mvn clean package -DskipTests
cd ..

# ç¼–è¯‘Flinkèšåˆä½œä¸š (éœ€è¦è¡¥å……å®Œæ•´ä»£ç )
echo "ç¼–è¯‘Flinkèšåˆä½œä¸š..."
cd flink-aggregation
# æ³¨æ„ï¼šéœ€è¦æ ¹æ® IMPLEMENTATION_GUIDE.md å®Œæˆæ ¸å¿ƒä»£ç 
mvn clean package -DskipTests
cd ..
```

---

## ğŸ“ æ­¥éª¤4: å¯åŠ¨æ•°æ®ç”Ÿæˆå™¨ (ç«‹å³å¯åŠ¨)

```bash
cd data-generator

# ä¿®æ”¹é…ç½®ï¼ˆå¯é€‰ï¼‰
# ç¼–è¾‘ src/main/resources/generator.properties
# data.total.count=10000          # æ€»è®¢å•æ•°
# data.rate.per.second=10         # æ¯ç§’ç”Ÿæˆè®¢å•æ•°

# å¯åŠ¨æ•°æ®ç”Ÿæˆå™¨
java -jar target/data-generator-1.0.jar

# æˆ–ä½¿ç”¨è„šæœ¬
chmod +x start.sh
./start.sh
```

æœŸæœ›è¾“å‡ºï¼š
```
[INFO] Data Generator Started
[INFO] Configuration - Total: 10000, Rate: 10/s
[INFO] Kafka Producer initialized
[INFO] [Progress] Generated: 100/10000, Messages: 350, Rate: 10/s
...
```

### éªŒè¯Kafkaæ•°æ®
```bash
# æ‰“å¼€æ–°ç»ˆç«¯ï¼ŒæŸ¥çœ‹è®¢å•ä¸»è¡¨æ•°æ®
kafka-console-consumer.sh --bootstrap-server slave1:9092 \
  --topic order-main-source --from-beginning --max-messages 5

# æŸ¥çœ‹è®¢å•æ˜ç»†æ•°æ®
kafka-console-consumer.sh --bootstrap-server slave1:9092 \
  --topic order-detail-source --from-beginning --max-messages 5
```

---

## ğŸ“ æ­¥éª¤5: æäº¤Flinkä½œä¸š (éœ€å®Œæˆä»£ç åæ‰§è¡Œ)

### æäº¤æ¸…æ´—ä½œä¸š
```bash
cd flink-cleansing

# ç¡®ä¿å·²å®Œæˆä»£ç å®ç°ï¼ˆå‚è€ƒ IMPLEMENTATION_GUIDE.mdï¼‰
# ä¿®æ”¹æäº¤è„šæœ¬ä¸­çš„è·¯å¾„
chmod +x submit-cleansing-job.sh

# æäº¤ä½œä¸š
./submit-cleansing-job.sh
```

æœŸæœ›è¾“å‡ºï¼š
```
Job has been submitted with JobID xxxxxxxx
```

### æäº¤èšåˆä½œä¸š
```bash
cd ../flink-aggregation

# ç¡®ä¿å·²å®Œæˆä»£ç å®ç°
chmod +x submit-aggregation-job.sh

# æäº¤ä½œä¸š
./submit-aggregation-job.sh
```

### æŸ¥çœ‹Flinkä½œä¸šçŠ¶æ€
è®¿é—® Flink Web UI: http://master1:8081

---

## ğŸ“ æ­¥éª¤6: éªŒè¯æ•°æ®æµè½¬

### æŸ¥çœ‹Kafkaå®½è¡¨æ•°æ®
```bash
# ç­‰å¾…Flinkä½œä¸šå¤„ç†åï¼ŒæŸ¥çœ‹å®½è¡¨
kafka-console-consumer.sh --bootstrap-server slave1:9092 \
  --topic order-wide-topic --from-beginning --max-messages 10
```

æœŸæœ›çœ‹åˆ°åŒ…å«ç”¨æˆ·å’Œå•†å“ç»´åº¦ä¿¡æ¯çš„å®½è¡¨JSONæ•°æ®ã€‚

### æŸ¥çœ‹ClickHouseèšåˆç»“æœ
```bash
clickhouse-client --host slave1
```

```sql
-- æŸ¥çœ‹æ—¶é—´çª—å£æŒ‡æ ‡
SELECT * FROM flink_metrics.metrics_time_window 
ORDER BY window_start DESC LIMIT 10;

-- æŸ¥çœ‹åˆ†ç±»Top10
SELECT * FROM flink_metrics.metrics_category_top 
WHERE window_end = (SELECT MAX(window_end) FROM flink_metrics.metrics_category_top)
ORDER BY rank;

-- æŸ¥çœ‹ç”¨æˆ·ç­‰çº§ç»Ÿè®¡
SELECT * FROM flink_metrics.metrics_user_level 
WHERE window_end = (SELECT MAX(window_end) FROM flink_metrics.metrics_user_level)
ORDER BY user_level;
```

---

## ğŸ“ æ­¥éª¤7: é…ç½®Grafanaå¯è§†åŒ–

### å®‰è£…Grafana (å¦‚æœæœªå®‰è£…)
```bash
sudo yum install -y https://dl.grafana.com/oss/release/grafana-10.2.0-1.x86_64.rpm
sudo systemctl start grafana-server
sudo systemctl enable grafana-server
```

### å®‰è£…ClickHouseæ’ä»¶
```bash
sudo grafana-cli plugins install vertamedia-clickhouse-datasource
sudo systemctl restart grafana-server
sudo grafana-cli plugins ls
```

### é…ç½®æ•°æ®æº
1. è®¿é—® http://master1:3000
2. ç™»å½• (é»˜è®¤: admin/admin)
3. Configuration â†’ Data Sources â†’ Add data source
4. é€‰æ‹© **ClickHouse**
5. é…ç½®:
   - Name: `ClickHouse-Metrics`
   - URL: `http://slave1:8123`
   - Database: `flink_metrics`
   - Username: `default`
   - Password: (ç•™ç©º)
6. ç‚¹å‡» **Save & Test**

### åˆ›å»ºç¬¬ä¸€ä¸ªPanel
1. Create â†’ Dashboard â†’ Add new panel
2. é€‰æ‹©æ•°æ®æº: ClickHouse-Metrics
3. è¾“å…¥SQL:
```sql
SELECT 
    window_start AS time,
    order_count AS "è®¢å•æ•°"
FROM flink_metrics.metrics_time_window
WHERE window_type = '1min'
  AND window_start >= now() - INTERVAL 1 HOUR
ORDER BY time
```
4. Visualization: Time series
5. ç‚¹å‡» **Apply**

---

## âœ… éªŒæ”¶æ£€æŸ¥æ¸…å•

å®Œæˆä»¥ä¸Šæ­¥éª¤åï¼Œè¯·éªŒè¯ï¼š

- [ ] MySQLä¸­æœ‰100ä¸ªç”¨æˆ·å’Œ200ä»¶å•†å“
- [ ] ClickHouseä¸­æœ‰5å¼ æŒ‡æ ‡è¡¨
- [ ] Kafkaä¸­æœ‰3ä¸ªTopicï¼Œéƒ½æœ‰æ•°æ®æµå…¥
- [ ] æ•°æ®ç”Ÿæˆå™¨æ­£å¸¸è¿è¡Œï¼ŒæŒç»­ç”Ÿæˆæ•°æ®
- [ ] Flinkæ¸…æ´—ä½œä¸šæ­£å¸¸è¿è¡Œï¼ˆWeb UIå¯è§ï¼‰
- [ ] Flinkèšåˆä½œä¸šæ­£å¸¸è¿è¡Œï¼ˆWeb UIå¯è§ï¼‰
- [ ] Kafkaå®½è¡¨Topicä¸­èƒ½çœ‹åˆ°å®Œæ•´å®½è¡¨æ•°æ®
- [ ] ClickHouseå„æŒ‡æ ‡è¡¨ä¸­æœ‰èšåˆæ•°æ®
- [ ] Grafanaèƒ½è¿æ¥ClickHouseå¹¶å±•ç¤ºå›¾è¡¨

---

## ğŸ”§ å¸¸è§é—®é¢˜å¿«é€Ÿè§£å†³

### Q1: Mavenç¼–è¯‘å¤±è´¥
```bash
# æ¸…ç†å¹¶é‡æ–°ç¼–è¯‘
mvn clean
mvn install -DskipTests -U
```

### Q2: Kafkaè¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥KafkaæœåŠ¡
systemctl status kafka

# æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
telnet slave1 9092
```

### Q3: MySQLè¿æ¥è¢«æ‹’ç»
```bash
# æ£€æŸ¥MySQLæœåŠ¡
systemctl status mysqld

# æ£€æŸ¥é˜²ç«å¢™
firewall-cmd --zone=public --add-port=3306/tcp --permanent
firewall-cmd --reload

# æˆæƒè¿œç¨‹è®¿é—®
mysql -u root -p
GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'your_password';
FLUSH PRIVILEGES;
```

### Q4: ClickHouseæ— æ•°æ®
```bash
# æ£€æŸ¥Flinkä½œä¸šæ˜¯å¦æ­£å¸¸è¿è¡Œ
flink list -t yarn-per-job

# æŸ¥çœ‹TaskManageræ—¥å¿—
tail -f /opt/flink-1.19.3/log/*taskexecutor*.log
```

### Q5: Grafanaçœ‹ä¸åˆ°æ•°æ®
- æ£€æŸ¥æ—¶é—´èŒƒå›´æ˜¯å¦æ­£ç¡®
- æ£€æŸ¥SQLæ˜¯å¦æœ‰è¯­æ³•é”™è¯¯
- æ£€æŸ¥ClickHouseä¸­æ˜¯å¦çœŸçš„æœ‰æ•°æ®
- æŸ¥çœ‹Grafanaæ—¥å¿—: `sudo tail -f /var/log/grafana/grafana.log`

